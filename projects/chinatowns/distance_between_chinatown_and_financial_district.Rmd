---
title: "The Distance Between Chinatown and Financial District in Major U.S. Cities"
status: process
published: false
---

```{r setup, echo=FALSE, message=FALSE}
library(ggmap)
library(dplyr)
library(tidyr)
library(rvest)
library(stringr)
library(tibble)
library(zipcode)
```

I have lived in New York City and Boston, and have visited some other cities. In those cities, I
have noticed one thing, it seems that Chinatown is always close to the financial district.

Therefore, I want to do some simple analysis to see if that's always the case.

### List of Cities

I searched online and found this list: [10 best Chinatowns across the USA](http://www.usatoday.com/story/travel/destinations/2014/03/08/chinatown-chinese-asian-food/6173601/).

Then what I did was just some very very simple web scraping to get the city names and make them into a data frame.

```{r}
url <- "http://www.usatoday.com/story/travel/destinations/2014/03/08/chinatown-chinese-asian-food/6173601/"

usa_news <- read_html(url)
city <- usa_news %>% 
  html_nodes("b") %>% 
  html_text() %>% 
  tbl_df() %>% 
  filter(str_detect(value, "^\\d"), !str_detect(value, "Honolulu")) %>% 
  rename(city = value) %>% 
  mutate(city = str_replace(city, "^\\d{1,2}\\. ", ""))
city
```

Now I need to find where Chinatowns and the Financial Districts are located in those cities.

_Note: The reason I removed Honolulu is that I only want to consider the Contiguous United States._

### List of Zip Codes

Here I did some manual look-up to find the zip codes of Chinatowns and Financial Districts and add them to the __city__ data frame.

```{r}
ct_ft <- city %>% 
  bind_cols(
    tribble(
      ~Chinatown, ~Financial,
      "94108", "94111",
      "10013", "10038",
      "60616", "60605",
      "98104", "98104",
      "19107", "19103",
      "02111", "02110",
      "90012", "90071",
      "77036", "77002",
      "20001", "20433"
    )
  )
```

This is not ideal, as at first I was trying to programmatically find the polygon coordinates of those two areas, however, it seems that
Google Maps API doesn't support that, though Google apparently has that data:(.

Then I tried to use `geocode` function from `ggmap` package to get the zip codes:

```{r, eval=FALSE}
ct_fd <- city %>%
  mutate(city = str_replace(city, "^\\d{1,2}\\. ", ""),
         chinatown = str_c(city, " Chinatown"),
         financial_district = str_c(city, " Financial District")) %>%
  gather(area, query_name, -city) %>%
  arrange(city)


ct_fd_geo <- ct_fd %>%
  invoke_rows(function(query_name, ...) geocode(query_name, output = "more"), ., .to = "geo_code")
```

However, the problem here is that in certain cities, Chinatown and/or Financial District are not well-defined, and thus the above function would return some empty results.
Compromisingly, I had to do some research and find the zip codes. I tried to pick the zip code that's in the center of the area.

### Distances

To get the distances, I used the `mapdist` function from `ggmap` package.

```{r}
ct_ft_dist <- ct_ft %>% 
  bind_cols(
    ., 
    mapdist(.$Chinatown, .$Financial, mode = "walking", output = "simple")
  )
ct_ft_dist %>% arrange(km)
```

From the above, we could see that the distances are mostly within __3__ miles, and usually within __30__ minutes walk. The reason I chose to use __walking__ mode when measure distance is because walking is usually more flexible and traffic-free.

### Draw on Maps

At last, I also made some visualizations to show Chinatown and Financial Districts on city maps. I used the `zipcode` dataset from the `zipcode` package to get the __longitude__ and __latitude__ of those zip codes so that I could plot them on map.

```{r}
data("zipcode")

ct_ft_zips <- ct_ft %>% 
  gather(Area, zip, -city) %>% 
  left_join(zipcode %>% 
              select(-city),
            by = "zip") %>% 
  arrange(city)
```

Next, I created a function to map them on maps without having to write the similar code again and again.

```{r}
map_area <- function(city, state, zoom, size) {
  ggmap(get_map(str_c(city, ", ", state), zoom = zoom, maptype = "toner-lite", source = "google")) +
    geom_point(data = ct_ft_zips %>% filter(state == state), 
               aes(x = longitude, y = latitude, color = Area), size = size) +
    labs(x = "Longitude", y = "Latitude")
}
```

#### 1.Seattle

```{r}
map_area("Seattle", "WA", 13, 5)
```

#### 2.San Francisco
```{r}
map_area("San Francisco", "CA", 13, 5)
```

#### 3.Boston
```{r}
map_area("Boston", "MA", 14, 5)
```

#### 4.Los Angeles
```{r}
map_area("Los Angeles", "CA", 13, 5)
```

#### 5.Philadelphia
```{r}
map_area("Philadelphia", "PA", 14, 5)
```

#### 6.New York City
```{r}
map_area("Lower Manhattan", "NY", 14, 5)
```

#### 7.Washington, D.C.
```{r}
map_area("Washington", "DC", 14, 5)
```

#### 8.Chicago
```{r}
map_area("Chicago", "IL", 13, 5)
```

#### 9.Houston
```{r}
map_area("Houston", "TX", 11, 5)
```

### Summary

Objectively speaking, I am a little bit disappointed because they are not as close as I thought they would be, and especially in Houston, they are really far away from each other.

Subjectively speaking, there are some issues with this analysis:

* I wasn't able to get border coordinates of the two areas in all the cities

* In some cities, Financial Districts are not well-defined

* Sample size is small as there is still a lot of other major cities

* The _zoom_ settings are different in different cities when ploting points on map because the areas of those cities are different

* _Closesness_ is somewhat vague and objective, here I used the absolute distance, but I could also use relative distance, taking city size into account

The good thing is that this analysis gives me a chance to test my initial hypothesis, it doesn't matter if the result supports your hypothesis/theory or not, data analysis is always fun.